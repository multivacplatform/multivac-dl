{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Nets - Sentiment Analysis\n",
    "\n",
    "There is a branch of Deep Learning that is dedicated to processing time series. These deep Nets are **Recursive Neural Nets (RNNs)**. LSTMs are one of the few types of RNNs that are available. Gated Recurent Units (GRUs) are the other type of popular RNNs.\n",
    "\n",
    "This is an illustration from http://colah.github.io/posts/2015-08-Understanding-LSTMs/ (A highly recommended read)\n",
    "\n",
    "![RNNs](./images/RNN-unrolled.png)\n",
    "\n",
    "In lesson 5 we looked at getting the sentiment of a given movie review. The data comes from a IMDB review set where a rating of less than 5 was classified as negative and greater than 5 as positive. Neutral reviews were ignored.\n",
    "\n",
    "In the previous lesson we considered a Bag of Words (BoW) model where the emphasis is on how many times a particular word appeared in the sentence/ review. This worked fairly well giving around 80% accuracy.\n",
    "\n",
    "One thing that was missing was the structure of the sentence. The word order was not taken into account. For example a sentence such as this: \"I wanted to hate it so much but I loved the movie.\" would probably confuse the previous model. Simply because 'love' and 'hate' are both included in the sentence. There were other preprocessing steps done such as stemming (eg. hated -> hate, runner -> run) which will not be done in this lesson. We will maintain structure and feed in a number representation of words in order into our DL model.\n",
    "\n",
    "<img src=\"./images/happy_trump.png\" alt=\"happy\" style=\"width: 150px;\"/><img src=\"./images/sad_trump.png\" alt=\"sad\" style=\"width: 150px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, LSTM, Embedding, Reshape\n",
    "from keras.models import load_model, model_from_json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('data/reviews2.pkl'):\n",
    "    urllib.request.urlretrieve('https://www.dropbox.com/s/15tfttuzqe7fimg/reviews2.pkl?dl=1','data/reviews2.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing steps: lower case, remove urls, some punctuations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bromwell high is a cartoon comedy . it ran at ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>homelessness or houselessness as george carlin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brilliant overacting by lesley ann warren . be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is easily the most underrated film inn th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is not the typical mel brooks film . it w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews  Sentiment\n",
       "0  bromwell high is a cartoon comedy . it ran at ...          1\n",
       "1  homelessness or houselessness as george carlin...          1\n",
       "2  brilliant overacting by lesley ann warren . be...          1\n",
       "3  this is easily the most underrated film inn th...          1\n",
       "4  this is not the typical mel brooks film . it w...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('data/reviews2.pkl')\n",
    "df.Reviews = df.Reviews.str.lower()\n",
    "df.Reviews = df.Reviews.str.replace(r'http[\\w:/\\.]+','') # remove urls\n",
    "df.Reviews = df.Reviews.str.replace(r'[^\\.\\w\\s]','') #remove everything but characters and punctuation\n",
    "df.Reviews = df.Reviews.str.replace(r'\\.\\.+','.') #replace multple periods with a single one\n",
    "df.Reviews = df.Reviews.str.replace(r'\\.',' .') #replace multple periods with a single one\n",
    "df.Reviews = df.Reviews.str.replace(r'\\s\\s+',' ') #replace multple white space with a single one\n",
    "df.Reviews = df.Reviews.str.strip() \n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life such as teachers . my 35 years in the teaching profession lead me to believe that bromwell highs satire is much closer to reality than is teachers . the scramble to survive financially the insightful students who can see right through their pathetic teachers pomp the pettiness of the whole situation all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled . at . high . a classic line inspector im here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isnt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Reviews.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the unique words. We will only consider words that have been used more than 5 times. Finally from this we create a dictionary mapping words to integers.\n",
    "\n",
    "Once this is done we will create a list of reviews where the words are converted to ints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique words are:  27915\n",
      "The first review looks like this: \n",
      "[22054, 323, 6, 3, 1074, 217, 1, 8, 2102, 32, 0, 167, 59, 14, 47, 81, 5531, 43, 400, 118]\n"
     ]
    }
   ],
   "source": [
    "all_text = ' '.join(df.Reviews.values)\n",
    "words = all_text.split()\n",
    "u_words = Counter(words).most_common()\n",
    "u_words = [word[0] for word in u_words if word[1]>5] # we will only consider words that have been used more than 5 times\n",
    "# create the dictionary\n",
    "word2num = dict(zip(u_words,range(len(u_words))))\n",
    "word2num['<Other>'] = len(u_words)\n",
    "num2word = dict(zip(word2num.values(), word2num.keys()))\n",
    "\n",
    "int_text = [[word2num[word] if word in word2num else len(u_words) for word in Review.split()] for Review in df.Reviews.values]\n",
    "\n",
    "print('The number of unique words are: ', len(u_words))\n",
    "print('The first review looks like this: ')\n",
    "print(int_text[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnRAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff29c7ce2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(t) for t in int_text],50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of reviews greater than 500 in length is:  2234\n",
      "The number of reviews less than 50 in length is:  411\n"
     ]
    }
   ],
   "source": [
    "print('The number of reviews greater than 500 in length is: ', np.sum(np.array([len(t)>500 for t in int_text])))\n",
    "print('The number of reviews less than 50 in length is: ', np.sum(np.array([len(t)<50 for t in int_text])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You cannot pass differing lengths of sentences to the algorithm. Hence we shall prepad the sentence with `<PAD>`. Sequences less than 500 in length will be prepadded and sequences that are longer than 500 will be truncated. It is assumed that the sentiment of the review can be asserted from the first 500 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num2word[len(word2num)] = '<PAD>'\n",
    "word2num['<PAD>'] = len(word2num)\n",
    "\n",
    "for i, t in enumerate(int_text):\n",
    "    if len(t)<500:\n",
    "        int_text[i] = [word2num['<PAD>']]*(500-len(t)) + t\n",
    "    elif len(t)>500:\n",
    "        int_text[i] = t[:500]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "x = np.array(int_text)\n",
    "y = df.Sentiment.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Many to Many LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 32)          893344    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 918,241.0\n",
      "Trainable params: 918,241\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# TODO: Create the model\n",
    "# 1. Set an Embedding layer with an arbitary size for each word embedding\n",
    "# 2. Have an LSTM layer\n",
    "# 3. Connect the output of the LSTM layer to a Dense layer (what is the activation?)\n",
    "# 4. Compile it, what is the loss function? (see cheat sheet)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "22500/22500 [==============================] - 199s - loss: 0.5469 - acc: 0.7282   \n",
      "Epoch 2/2\n",
      "22500/22500 [==============================] - 197s - loss: 0.2779 - acc: 0.8920   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff259e68128>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "# TODO: train the model\n",
    "# use the .fit function to train it, use two epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The first number below is the loss and the second value onwards is whatever metrics you have used, in this case it is the accuracy. Important to set the `batch_size` as well since evaluation can be slower for default size (32).\n",
    "\n",
    "The `.evaluate` function is similar to `.predict` except for the fact that you provide what y is. Therefore it takes care of figuring out the metrics for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 5s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36751551814079286, 0.85960000066757203]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
